{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare for datasets\n"
   ],
   "metadata": {
    "collapsed": false,
    "id": "wjWri0Jgl1lY",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Packages"
   ],
   "metadata": {
    "collapsed": false,
    "id": "zt_x2g8ol1lb",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "id": "Pvor-ddKl1lc",
    "outputId": "23159a71-b797-445a-d70c-4eff45146439",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1)\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load the Training and Test Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "id": "nxLmTjk7l1ld",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class text_loader:\n",
    "    def __init__(self, train_address, test_address, split):\n",
    "        if not os.path.exists(train_address):\n",
    "            print(f\"Path: {train_address} does not exist\")\n",
    "            return None\n",
    "        if not os.path.exists(test_address):\n",
    "            print(f\"Path: {test_address} does not exist\")\n",
    "            return None\n",
    "        self.train_address = train_address\n",
    "        self.test_address = test_address\n",
    "        self.split = split\n",
    "        if self.split:\n",
    "            self.en_train, self.unknown_train, self.en_val, self.unknown_val= self.read_sentences(train_address, split=self.split)\n",
    "        else:\n",
    "            self.en_train, self.unknown_train = self.read_sentences(train_address, split=self.split)\n",
    "        self.left_test, self.right_test = self.read_sentences(test_address)\n",
    "        self.char2byte = self.get_char2byte()\n",
    "        self.byte2char = self.get_byte2char()\n",
    "\n",
    "\n",
    "    def read_sentences(self, file_address, split=False):\n",
    "        l_sentences = []\n",
    "        r_sentences = []\n",
    "        sentences = []\n",
    "        with open(file_address, 'br') as f:\n",
    "            for line in f:\n",
    "                line = line.decode(\"latin-1\")\n",
    "                # line = re.sub(r\"(?:\\\\x[A-Fa-f0-9]{2})\", \"\", line)\n",
    "                line = line.replace(\"\\\\n\", \"\")\n",
    "                line = line[0:-1]\n",
    "                if split:\n",
    "                    sentences.append(line)\n",
    "                else:\n",
    "                    line = re.split(\"\\t\", line)\n",
    "                    if line[0] != line[1]:\n",
    "                        l_sentences.append(line[0])\n",
    "                        r_sentences.append(line[1])\n",
    "        if split:\n",
    "            random.shuffle(sentences)\n",
    "            l_sentences = []\n",
    "            r_sentences = []\n",
    "            for line in sentences:\n",
    "                line = re.split(\"\\t\", line)\n",
    "                if line[0] != line[1]:\n",
    "                    l_sentences.append(line[0])\n",
    "                    r_sentences.append(line[1])\n",
    "            split_ind = int(0.9 * len(sentences))\n",
    "            en_train = l_sentences[:split_ind]\n",
    "            en_val = l_sentences[split_ind:]\n",
    "            unknown_train = r_sentences[:split_ind]\n",
    "            unknown_val = r_sentences[split_ind:]\n",
    "            return en_train, unknown_train, en_val, unknown_val\n",
    "        else:\n",
    "            return l_sentences, r_sentences\n",
    "\n",
    "\n",
    "    def get_char2byte_from_raw(self, lines, char2byte: dict):\n",
    "        for line in tqdm(lines):\n",
    "            for char in line:\n",
    "                char2byte[char] = ord(char)\n",
    "\n",
    "\n",
    "    def get_char2byte(self):\n",
    "        char2byte = dict()\n",
    "        self.get_char2byte_from_raw(self.en_train, char2byte)\n",
    "        self.get_char2byte_from_raw(self.unknown_train, char2byte)\n",
    "        self.get_char2byte_from_raw(self.left_test, char2byte)\n",
    "        self.get_char2byte_from_raw(self.right_test, char2byte)\n",
    "        return char2byte\n",
    "\n",
    "\n",
    "    def get_byte2char(self):\n",
    "        return {b: c for c, b in self.char2byte.items()}\n",
    "\n",
    "\n",
    "    def get_data(self):\n",
    "        if self.split:\n",
    "            return self.en_train, self.unknown_train, self.en_val, self.unknown_val, self.left_test, self.right_test, self.char2byte, self.byte2char\n",
    "        else:\n",
    "            return self.en_train, self.unknown_train, self.left_test, self.right_test, self.char2byte, self.byte2char"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "hcfSIJSol1le"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "id": "Tf5b9FgUl1le",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900000/900000 [00:06<00:00, 141669.88it/s]\n",
      "100%|██████████| 900000/900000 [00:06<00:00, 138194.25it/s]\n",
      "100%|██████████| 100000/100000 [00:00<00:00, 140314.89it/s]\n",
      "100%|██████████| 100000/100000 [00:00<00:00, 141084.27it/s]\n"
     ]
    }
   ],
   "source": [
    "train_address = f\"./data/src/train.txt\"\n",
    "test_address = f\"./data/src/test.rand.txt\"\n",
    "data = text_loader(train_address, test_address, True)\n",
    "en_train, unknown_train, en_val, unknown_val, left_test, right_test, char2byte, byte2char = data.get_data()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "1U-vOqGul1lf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### bytes.txt"
   ],
   "metadata": {
    "collapsed": false,
    "id": "7PgjoIQ5l1lf",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "my_vocab = set(char2byte.values())\n",
    "my_vocab = sorted(list(my_vocab))\n",
    "vocab_path = f\"./data/bytes.txt\"\n",
    "if os.path.exists(vocab_path):\n",
    "    os.remove(vocab_path)\n",
    "else:\n",
    "    with open(vocab_path, \"w\") as f:\n",
    "        for b in tqdm(my_vocab):\n",
    "            f.write(str(f\"{b}\\n\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### char2byte.pkl"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('char2byte.pkl', 'wb') as handle:\n",
    "    pickle.dump(char2byte, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def store_lines_into_file(filename: str, lines: list):\n",
    "    with open(filename, \"w\", encoding=\"latin-1\") as f:\n",
    "        for line in lines:\n",
    "            f.write(line + '\\n')\n",
    "\n",
    "def run_store(filename: str, lines: list):\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)\n",
    "    store_lines_into_file(filename, lines)\n",
    "\n",
    "\n",
    "filenames = [f\"./data/en_train.txt\", f\"./data/en_val.txt\", f\"./data/unknown_train.txt\", f\"./data/unknown_val.txt\", f\"./data/left_test.txt\", f\"./data/right_test.txt\"]\n",
    "run_store(filenames[0], en_train)\n",
    "# run_store(filenames[1], en_val)\n",
    "run_store(filenames[2], unknown_train)\n",
    "# run_store(filenames[3], unknown_val)\n",
    "run_store(filenames[4], left_test)\n",
    "run_store(filenames[5], right_test)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "KoOkmlpWl1lg"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "900000it [02:48, 5349.44it/s]\n"
     ]
    }
   ],
   "source": [
    "train_byte_rows_str = []\n",
    "train_byte_rows_list = []\n",
    "train_ltb = []\n",
    "train = []\n",
    "for idx, (l1, l2) in tqdm(enumerate(zip(en_train, unknown_train))):\n",
    "    new_l1_str = \"\"\n",
    "    new_l1_list = []\n",
    "    new_l2_str = \" \"\n",
    "    new_l2_list = []\n",
    "    for c1, c2 in zip(l1, l2):\n",
    "        new_l1_str = new_l1_str + str(char2byte[c1]) + \" \"\n",
    "        new_l2_str = new_l2_str + str(char2byte[c2]) + \" \"\n",
    "        new_l1_list.append(char2byte[c1])\n",
    "        new_l2_list.append(char2byte[c2])\n",
    "    if new_l1_str != new_l2_str:\n",
    "        # byte_rows_str.append([new_l1_str, new_l1_str, new_l2_str])\n",
    "        train_ltb.append(['1', '', f'{new_l1_str}'])\n",
    "        train_ltb.append(['2', '', f'{new_l2_str}'])\n",
    "        temp1 = []\n",
    "        temp2 = []\n",
    "        l1_str = \"\"\n",
    "        l2_str = \"\"\n",
    "        meet = False\n",
    "        curr = -1\n",
    "        for i, (byte1, byte2) in enumerate(zip(new_l1_list, new_l2_list)):\n",
    "            if byte1 != byte2:\n",
    "                if not meet:\n",
    "                    # print(i)\n",
    "                    # print(max(0, i-5))\n",
    "                    temp1.extend(new_l1_list[max(0, i-5):i+1])\n",
    "                    temp2.extend(new_l2_list[max(0, i-5):i+1])\n",
    "                    meet = True\n",
    "                    curr = i+1\n",
    "                else:\n",
    "                    temp1.extend(new_l1_list[max(curr, i-5):i+1])\n",
    "                    temp2.extend(new_l2_list[max(curr, i-5):i+1])\n",
    "                    curr = i+1\n",
    "        temp1.extend(new_l1_list[curr:min(curr+5, len(new_l1_list))])\n",
    "        temp2.extend(new_l2_list[curr:min(curr+5, len(new_l2_list))])\n",
    "        for byte1 in temp1:\n",
    "            l1_str += str(byte1) + \" \"\n",
    "        for byte2 in temp2:\n",
    "            l2_str += str(byte2) + \" \"\n",
    "        train.append(['1', '', f'{l1_str}'])\n",
    "        train.append(['2', '', f'{l2_str}'])\n",
    "        # train_byte_row_json = json.dumps({'id': idx, 'en': new_l1_list, 'unknown': new_l2_list})\n",
    "        # train_byte_rows_list.append(json.loads(train_byte_row_json))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### train.csv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1800000/1800000 [00:06<00:00, 274509.99it/s]\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"./data/train.csv\"):\n",
    "    os.remove(\"./data/train.csv\")\n",
    "with open('./data/train.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # writer.writerow(header)\n",
    "    for ltb in tqdm(train):\n",
    "        writer.writerow(ltb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:18, 5516.75it/s]\n"
     ]
    }
   ],
   "source": [
    "test_byte_rows_str = []\n",
    "test_byte_rows_list = []\n",
    "test_ltb = []\n",
    "test = []\n",
    "for idx, (l1, l2) in tqdm(enumerate(zip(en_val, unknown_val))):\n",
    "    new_l1_str = \"\"\n",
    "    new_l1_list = []\n",
    "    new_l2_str = \" \"\n",
    "    new_l2_list = []\n",
    "    for c1, c2 in zip(l1, l2):\n",
    "        new_l1_str = new_l1_str + str(char2byte[c1]) + \" \"\n",
    "        new_l2_str = new_l2_str + str(char2byte[c2]) + \" \"\n",
    "        new_l1_list.append(char2byte[c1])\n",
    "        new_l2_list.append(char2byte[c2])\n",
    "    if new_l1_str != new_l2_str:\n",
    "        # byte_rows_str.append([new_l1_str, new_l1_str, new_l2_str])\n",
    "        test_ltb.append(['1', '', f'{new_l1_str}'])\n",
    "        test_ltb.append(['2', '', f'{new_l2_str}'])\n",
    "        temp1 = []\n",
    "        temp2 = []\n",
    "        l1_str = \"\"\n",
    "        l2_str = \"\"\n",
    "        meet = False\n",
    "        curr = -1\n",
    "        for i, (byte1, byte2) in enumerate(zip(new_l1_list, new_l2_list)):\n",
    "            if byte1 != byte2:\n",
    "                if not meet:\n",
    "                    # print(i)\n",
    "                    # print(max(0, i-5))\n",
    "                    temp1.extend(new_l1_list[max(0, i-5):i+1])\n",
    "                    temp2.extend(new_l2_list[max(0, i-5):i+1])\n",
    "                    meet = True\n",
    "                    curr = i+1\n",
    "                else:\n",
    "                    temp1.extend(new_l1_list[max(curr, i-5):i+1])\n",
    "                    temp2.extend(new_l2_list[max(curr, i-5):i+1])\n",
    "                    curr = i+1\n",
    "        temp1.extend(new_l1_list[curr:min(curr+5, len(new_l1_list))])\n",
    "        temp2.extend(new_l2_list[curr:min(curr+5, len(new_l2_list))])\n",
    "        for byte1 in temp1:\n",
    "            l1_str += str(byte1) + \" \"\n",
    "        for byte2 in temp2:\n",
    "            l2_str += str(byte2) + \" \"\n",
    "        test.append(['1', '', f'{l1_str}'])\n",
    "        test.append(['2', '', f'{l2_str}'])\n",
    "        # test_byte_row_json = json.dumps({'id': idx, 'en': new_l1_list, 'unknown': new_l2_list})\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### test.csv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [00:00<00:00, 286519.27it/s]\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"./data/test.csv\"):\n",
    "    os.remove(\"./data/test.csv\")\n",
    "with open('./data/test.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # writer.writerow(header)\n",
    "    for ltb in tqdm(test):\n",
    "        writer.writerow(ltb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Finished preprossing dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "name": "part1.ipynb",
   "provenance": [],
   "collapsed_sections": [
    "YEC2mrYEl1lj",
    "Dbaorjrel1lj",
    "sG6Cingbl1lk",
    "zcg_wt97l1lk",
    "FObK00U2l1lo",
    "BfiU5upfl1lp",
    "roIpD7IPl1lp",
    "409WpDVfl1lq"
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}